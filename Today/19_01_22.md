TIL :: 19_01_22

### Hypervisor
- 호스트 컴퓨터 1대에서 다수의 운영체제를 동시에 실행 시킬 수 있는 가상 플랫폼 기술
- 물리 서버를 가상화 환경을 만들기 위해 필요한 기술
- Native (bare metal)
  - 하드웨어에 직접 설치 되어 있는 방식
- Hosted 
  - 프로그램으로 설치 되어 있는 방식

### docker
- 시스템 전반을 가상화 하는 hypervisor와 달리 docker는 application이 구동 될 수 있는 환경만 가상화
- 격리된 프로세스, kernel을 공유
- application이 동작 할 수 있도록 CPU, memory를 가상화하고 구동하는데 필요한 운영체제나 라이브러리는 공유
- 속도가 빠르고 자원 효율성이 좋다 (hypervisor 위에 게스트 os뿐만 아니라 라이브러리 설치 구동 동작에 대한 자원 소모가 없으므로)
- 외부에서 docker container 내부로 접속하려면 host단에서 포트 포워딩이 필요
  - 도커엔진이 설치된 호스트 에선 docker0 interface를 통해 docker와 통신
  - container는 NAT를 통해 ip를 부여 받고 특별한 설정이 없으면 172.17.0.x/8
- host의 볼륨을 마운트 했을 때 docker container내 이미 파일이 존재한다면 host의 volume이 덮어쓴다

### 클라우드 vs 가상화
- 가상화는 하드웨어 기능을 분리하는 기술
- 클라우드 이러한 가상화를 사용하는 기술

### cloud computing
- 인터넷이 가능한 디바이스를 통해 클라우드란 제 3의 공간을 활용해 데이터를 일고 쓰고 분석 처리하여 저장하고 관리하는 컴퓨팅 시스템
- IaaS (Infrastructure as a Service)
- PaaS (Platform as a Service)
- SaaS (Service as a Service)

### linux tcp 관련 kernel parameter
```bash
$ sysctl // sysctl를 활용해 kernel parameter를 런타임 중에 변경 할 수 있다
$ sysctl -a // list up kernel parameter
```

- TCP capacity와 bandwidth를 tuning하는 kernel parameter에 대해서 알아보자
  - TCP와 관련된 kernel parameter들은 대부분 net.core, net.ipv4, net.ipv6 prefix를 가지고 있다.
```bash
$ sysctl -a | grep net.core
$ sysctl -a | grep net.ipv4
$ sysctl -a | grep net.ipv6
```
- '-w'를 활용해 kernel parameter 설정
```bash
$ sysctl -w net.core.wmem_max="16777216"
```
- 시스템 부팅 시 설정 값을 적용 하려면 /etc/sysctl.conf 파일에 해당 설정 기입

- bandwidth관련 kernel parameter
  - TCP window scaling
    - 실제 인터넷 망에선 BDP가 recevier window size를 충분히 cover한다. 즉 BDP == receiver window size라 생각 할 수 있다
    - 즉, bandwidth = (receiver window size) / RTT
    - RTT는 peer간 거리에 종속적이라 줄이기 힘들다
    - bandwidth를 높이려면 recevier window size를 높이자!
    - 기본적으로 TCP 연결을 맺을 땐 SYN 패킷에 receiver window size를 advertising
    - 보통 receiver window size는 0~65,535(64KB)로 작다
    - TCP header의 window scale이란 값을 통해 receiver window size를 높일 수 있다.
      - window scale
        - 0 ~ 14 사이의 값을 가진다.
        - window scale의 값이 n이면 2^n 값을 window scaling factor라 한다.
    - window scale값을 세팅하면 실제 (receiver window size) * (window scaling factor)로 receiver window size를 증가 시킬 수 있다.
    - TCP window scaling을 사용할 때 최대 receiver window size는 65,535 * 2^14 := 1G다.
    - TCP window scaling 활성화 (통신하는 두 host가 TCP window scaling이 활성화 되어 있어야 한다.)
    - ```bash
      $ sysctl -w net.ipv4.tcp_window_scaling="1"
      ```
  - TCP socket buffer size
    - net.core.rmem_default
    - net.core.wmem_default
    - net.core.rmem_max
    - net.core.wmem_max
    - net.ipv4.tcp_rmem
    - net.ipv4.tcp_wmem
    - 
    - rmem, wmem은 read(receive) buffer, write(send) buffer, 단위는 byte
    - core는 TCP를 포함한 모든 종류의 소켓
    - ipv4는 tcp socket 일부 parameter는 ipv6에도 적용됨
    - 각 kernel parameter는 default, min, max
      - min: TCP memory pressure일 때 가지는 값
      - max: 가질 수 있는 최대값
      - default: core의 default값을 따른다.

  - congestion window size


- 용어정리
  - RTT (Round Trip Time) : 한 host에서 다른 host까지 패킷이 왕복하는데 걸리는 시간 (peer간 물리적이 거리에 종속적)
  ```bash
  $ ping google.com -c 3
  PING google.com (172.217.26.14): 56 data bytes
  64 bytes from 172.217.26.14: icmp_seq=0 ttl=53 time=30.483 ms
  64 bytes from 172.217.26.14: icmp_seq=1 ttl=53 time=30.711 ms
  64 bytes from 172.217.26.14: icmp_seq=2 ttl=53 time=33.222 ms

  --- google.com ping statistics ---
  3 packets transmitted, 3 packets received, 0.0% packet loss
  round-trip min/avg/max/stddev = 30.483/31.472/33.222/1.241 ms
  ```
  - BDP (Bandwidth delay product)
    - 어떤 네트워크 경로에 전달 중인 데이터의 양
    - RTT * bandwidth
    - bandwidth = BDP / RTT